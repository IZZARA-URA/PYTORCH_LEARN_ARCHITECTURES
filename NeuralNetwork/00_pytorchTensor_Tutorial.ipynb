{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "###################################################################################\n",
    "#                               Initializing Tensor                               #\n",
    "###################################################################################\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tensor = torch.tensor([[1,2,3],[4,5,6]], dtype = torch.float32, \n",
    "                      device=device,\n",
    "                      requires_grad=True)\n",
    "# tensor\n",
    "# tensor.dtype\n",
    "# tensor.device\n",
    "# tensor.shape\n",
    "# tensor.requires_grad\n",
    "\n",
    "# Other common initialization method\n",
    "x = torch.empty(size = (3, 3))\n",
    "x = torch.zeros((3, 3))\n",
    "x = torch.rand((3, 3))\n",
    "x = torch.ones((3,3))\n",
    "x = torch.eye(5, 5)\n",
    "x = torch.arange(start=0, end=5, step=1)\n",
    "x = torch.linspace(start=0.1, end=1, steps=10)\n",
    "x = torch.empty(size=(1,5)).normal_(mean=0, std=1)\n",
    "x = torch.empty(size=(1,5)).uniform_(0, 1)\n",
    "x = torch.diag(torch.ones(3))\n",
    "# x nge()\n",
    "\n",
    "\n",
    "tensor = torch.arange(4)\n",
    "# tensor.bool()\n",
    "# tensor.short()\n",
    "# tensor.long()\n",
    "# tensor.half()\n",
    "# tensor.float()\n",
    "# tensor.double()\n",
    "\n",
    "# conversion Tensor and Array\n",
    "import numpy as np\n",
    "np_array = np.zeros((5, 5))\n",
    "tensor = torch.from_numpy(np_array)\n",
    "np_array_back = tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: An output with one or more elements was resized since it had shape [], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "###################################################################################\n",
    "#                          Tensor Math & Comparison Operations                    #\n",
    "###################################################################################\n",
    "\n",
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor([4, 5, 6])\n",
    "\n",
    "z1 = torch.empty(3)\n",
    "torch.add(x,y, out=32)\n",
    "\n",
    "z3 = torch.add(x, y)\n",
    "\n",
    "#Addition\n",
    "z = x + y\n",
    "\n",
    "# Subtaction\n",
    "z = x - y \n",
    "\n",
    "# Division \n",
    "z = torch.true_divide(x, y) # element wise\n",
    "\n",
    "# Implace operations \n",
    "t = torch.zeros(3)\n",
    "t.add_(x)\n",
    "t += x # t = t + x\n",
    "\n",
    "# Exponentiation \n",
    "z = x.pow(2)\n",
    "z = x ** 2 \n",
    "\n",
    "# Matrix Multiplication \n",
    "x1 = torch.rand((2, 5))\n",
    "x2 = torch.rand((5, 3))\n",
    "x3 = torch.mm(x1, x2)\n",
    "x3 = x1.mm(x2)\n",
    "\n",
    "# Matrix Exponentiation \n",
    "matrix_exp = torch.rand(5, 5)\n",
    "\n",
    "\n",
    "# Element wise nult \n",
    "z = x * y\n",
    "\n",
    "# Dot product \n",
    "z = torch.dot(x, y)\n",
    "# print(z)\n",
    "\n",
    "# Batch Matrix Multiplication \n",
    "batch = 32 \n",
    "n = 10 \n",
    "m= 20 \n",
    "p = 30\n",
    "\n",
    "tensor_1 = torch.rand((batch, n, m)) # 32 batch [n x m]\n",
    "tensor_2 = torch.rand((batch, m, p))\n",
    "out_bmm = torch.bmm(tensor_1, tensor_2)\n",
    "# print(out_bmm)\n",
    "\n",
    "\n",
    "# Broadcasting \n",
    "x1 = torch.rand((5, 5))\n",
    "x2 = torch.rand((1, 5))\n",
    "\n",
    "z = x1 - x2 \n",
    "z = x1 ** x2\n",
    "\n",
    "# print(z)\n",
    "\n",
    "\n",
    "# Usefull Tensor Methid Operations \n",
    "sum_x = torch.sum(x, dim=0)\n",
    "value, indices = torch.min(x, dim=0)\n",
    "value, indices = torch.max(x, dim=0)\n",
    "abs_x = torch.abs(x)\n",
    "z = torch.argmax(x, dim=0)\n",
    "z = torch.argmin(x, dim=0)\n",
    "mean_x = torch.mean(x.float(), dim=0)\n",
    "z = torch.eq(x, y)\n",
    "sorted_y = torch.sort(y, dim=0, descending=False)\n",
    "# print(sorted_y)\n",
    "\n",
    "z = torch.clamp(x, min=0)\n",
    "# print(z)\n",
    "x = torch.tensor([1,0,1,1,1,0], dtype=torch.bool)\n",
    "# print(x)\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 10 \n",
    "features = 25 \n",
    "x = torch.rand((batch_size, features))\n",
    "# print(x)\n",
    "# print(x[0].shape) # x[0, :]\n",
    "# print(x[:, 0].shape\n",
    "# print(x[2, 0:10]) # 0:1 -> [0,1,2,3,...,9]     third row\n",
    "x[0,0] = 100\n",
    "\n",
    "x = torch.arange(10)\n",
    "# print(x)\n",
    "indices = [2,5,8]\n",
    "# print(x[indices])\n",
    "\n",
    "x = torch.rand((3,5))\n",
    "rows = torch.tensor([1, 0])\n",
    "cols = torch.tensor([4, 0])\n",
    "# print(x[rows, cols])\n",
    "\n",
    "x = torch.arange(10)\n",
    "print(x)\n",
    "# print(x[(x<2)|(x>8)])\n",
    "# print(x[x.remainder(2) == 0])\n",
    "\n",
    "# Useful Operations \n",
    "# print(torch.where(x > 6, x, x*2))\n",
    "# print(torch.tensor([0,0,3,6,2,4,6,2]).unique())\n",
    "# print(x.ndimension())\n",
    "# print(x.numel())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "torch.Size([10, 1])\n",
      "tensor([[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]])\n",
      "tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "###################################################################################\n",
    "#                                  Tensor Reshaping                               #\n",
    "###################################################################################\n",
    "\n",
    "x = torch.arange(9)\n",
    "\n",
    "x_3x3 = x. view(3, 3)   # use memory\n",
    "# print(x_3x3)\n",
    "x_3x3 = x.reshape(3, 3) # \n",
    "# print(x_3x3)\n",
    "\n",
    "y = x_3x3.t() # transpose\n",
    "# print(y.contiguous().view(9))\n",
    "\n",
    "x1 = torch.rand((2, 5))\n",
    "x2 = torch.rand((2, 5))\n",
    "\n",
    "# print(torch.cat((x1,x2), dim=0).shape)\n",
    "# print(torch.cat((x1,x2), dim=1).shape)\n",
    "\n",
    "\n",
    "# print(x1.shape)\n",
    "\n",
    "z = x1.view(-1) # flatten \n",
    "# print(z.shape)\n",
    "\n",
    "\n",
    "batch = 64\n",
    "x = torch.rand((batch, 2, 5))\n",
    "z = x.view(batch, -1)\n",
    "# print(x)\n",
    "# print(z.shape)\n",
    "\n",
    "\n",
    "\n",
    "z = x.permute(0, 2, 1)\n",
    "# print(z.shape)\n",
    "\n",
    "x = torch.arange(10)\n",
    "print(x.unsqueeze(0).shape)\n",
    "print(x.unsqueeze(1).shape)\n",
    "\n",
    "x = torch.arange(10).unsqueeze(0).unsqueeze(1)\n",
    "print(x)\n",
    "z = x.squeeze(1)\n",
    "print(z)\n",
    "print(z.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
